# LLMs Privacy Literature

A curated list of LLMs security research
 papers.

Paper  are divided into three categories: motivation, possible dataset and methods design and sorted by their released dates in descending order.


## Quick Links
**Motivation:** [Link](#motivation-back-to-top)  
**Text Anonymization:** [Link](#text-anonymization-back-to-top)  
**Prompt attack:** [Link](#prompt-attack-back-to-top)  
**Jailbreak attack:** [Link](#jailbreak-attack-back-to-top)   
**De-identification and anonymization of medical reports:** [Link](#de-identification-and-anonymization-of-medical-reports-back-to-top)  
**Prompt Learning** [Link](#prompt-learning-back-to-top)   
**Text Generation** [Link](#text-generation-back-to-top)  

## Motivation [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Beyond Memorization: Violating Privacy Via Inference with Large Language Models** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2310.07298v1.pdf) | unknown |
## Text Anonymization [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2022 | **DP-VAE: Human-Readable Text Anonymization for Online Reviews with Differentially Private Variational Autoencoders** | WWW’22 | unknown | ACM | [Link](https://dl.acm.org/doi/10.1145/3485447.3512232) | unknown |

## Prompt attack [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Prompt Injection Attacks and Defenses in LLM-Integrated Applications** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2310.12815.pdf) | [Link](https://github.com/liu00222/Open-Prompt-Injection) |
| 2023 | **PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts** | unknown | unknown  | arXiv | [Link](https://arxiv.org/pdf/2306.04528.pdf) | [Link](https://github.com/microsoft/promptbench) |



## De-identification and anonymization of medical reports [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation into Input Regurgitation and Prompt-Induced Sanitization** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2305.15008.pdf) | unknown |
| 2023 | **DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2303.11032.pdf) | unknown |
  

## Jailbreak attack [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **ON THE SAFETY OF OPEN-SOURCED LARGE LANGUAGE MODELS: DOES ALIGNMENT REALLY PREVENT THEM FROM BEING MISUSED?** | unknown | Jailbreak  | arXiv | [Link](https://arxiv.org/pdf/2310.01581.pdf) | unknown |
| 2023 | **“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models** | unknown | unknown | arXiv | unknown |
| 2023 | **“MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2307.08715.pdf) | unknown | 
| 2023 | **“Universal and Transferable Adversarial Attacks on Aligned Language Models** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2307.15043.pdf) | unknown | 
| 2023 | **“SneakyPrompt: Jailbreaking Text-to-image Generative Models** | IEEE S&P 2024 | unknown | arXiv | [Link](https://arxiv.org/pdf/2305.12082.pdf) | [Link](https://github.com/Yuchen413/text2image-safety) | 
      
## Prompt Learning [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content?** | S&P | unknown  | arXiv | [Link](https://arxiv.org/pdf/2308.05596.pdf) | [Link](https://github.com/xinleihe/toxic-prompt) |
| 2021 | **The Power of Scale for Parameter-Efficient Prompt Tuning** | unknown | unknown  | arXiv | [Link](https://arxiv.org/pdf/2104.08691.pdf) | unknown |

## Text Generation [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Type  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2021 | **Pretrained Language Models for Text Generation: A Survey** | ACM  | survey  | arxiv | [Link](https://arxiv.org/pdf/2201.05273.pdf) | unknown |
| 2021 | **Automatic text summarization: A comprehensive survey** | Expert Syst. Appl. (2021)| survey | ScienceDirect | [Link](https://www.sciencedirect.com/science/article/pii/S0957417420305030) | unknown |
| 2022 | **ParaDetox: Detoxification with Parallel Data** | ACL | paper  | acl | [Link](https://aclanthology.org/2022.acl-long.469.pdf) | unknown |
| 2023 | **A Systematic survey on automated text generation tools and techniques: application, evaluation, and challenges** | MULTIMED TOOLS APPL| survey | springer | [Link](https://link.springer.com/article/10.1007/s11042-023-15224-0) | unknown |
