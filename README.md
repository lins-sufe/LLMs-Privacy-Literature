# LLMs Privacy Literature

A curated list of LLMs security research
 papers.

Paper  are divided into three categories: motivation, possible dataset and methods design and sorted by their released dates in descending order.


## Quick Links
**Motivation:** [Link](#motivation-back-to-top)   
**Prompt attack:** [Link](#prompt-attack-back-to-top)  
**Model attack:** [Link](#model-attack-back-to-top)   
**De-identification and anonymization of medical reports:** [Link](#de-identification-and-anonymization-of-medical-reports-back-to-top)

## Motivation [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Beyond Memorization: Violating Privacy Via Inference with Large Language Models** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2310.07298v1.pdf) | unknown |


## Prompt attack [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Prompt Injection Attacks and Defenses in LLM-Integrated Applications** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2310.12815.pdf) | [Link](https://github.com/liu00222/Open-Prompt-Injection) |
| 2023 | **PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2306.04528.pdf) | [Link](https://github.com/microsoft/promptbench) |


## De-identification and anonymization of medical reports [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation into Input Regurgitation and Prompt-Induced Sanitization** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2305.15008.pdf) | unknown |
| 2023 | **DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2303.11032.pdf) | unknown |
  

## Model attack [[Back to Top](#llms-privacy-literature)]

| Year   | Title |  Conference | Field  |   Venue  | Paper Link  | Code Link |
|-------|--------|--------|--------|-----------|------------|---------------|
| 2023 | **ON THE SAFETY OF OPEN-SOURCED LARGE LANGUAGE MODELS: DOES ALIGNMENT REALLY PREVENT THEM FROM BEING MISUSED?** | unknown | unknown | arXiv | [Link](https://arxiv.org/pdf/2310.01581.pdf) | unknown |
      
      
